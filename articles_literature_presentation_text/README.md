[Ссылка на презентацию]([https://www.google.com](https://docs.google.com/presentation/d/1RZeNEXYrcnuPTD-LqarVNCz0Z1zmET0Uk2Z3OrIo8jI/edit?slide=id.g3aa0598f5ac_2_170#slide=id.g3aa0598f5ac_2_170))
Статьи
1) **Scaling Up RL: Unlocking Diverse Reasoning in LLMs via Prolonged Training:** [arXiv:2507.12507](https://arxiv.org/abs/2507.12507) (Масштабирование обучения с подкреплением на основе проверяемой обратной связи **(RLVF)** на триллионы токенов, что приводит к значительному улучшению способностей к рассуждению в различных областях без ущерба для языковых навыков.)
2) **rStar-Math: Small LLMs Can Master Math Reasoning with Self-Evolved Deep Thinking**: [arXiv:2501.04519](https://arxiv.org/abs/2501.04519) (**RSA** — рекурсивная само-агрегация множественных траекторий рассуждений для углубленного мышления **(не MCTS)**)
3) **Supervised Reinforcement Learning: From Expert Trajectories to Step-wise Reasoning:** 	[arXiv:2510.25992](https://arxiv.org/abs/2510.25992) (Гибридный метод, сочетающий обучение на экспертных траекториях (Supervised Learning) с пошаговым вознаграждением (Reinforcement Learning) для обучения сложным рассуждениям **(SRL)**)
4) **Does Math Reasoning Improve General LLM Capabilities? Understanding Transferability of LLM Reasoning:** [arXiv:2507.00432](https://arxiv.org/abs/2507.00432) (SFT не позволяет обобщать модель между областями математики, в отличии от RL, благодаря которому модель может решать задачи из других доменов)
5) **Recursive Self-Aggregation Unlocks Deep Thinking in Large Language Models**: [arXiv:2509.26626](https://arxiv.org/abs/2509.26626) **(RSA)**
